{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skck0226/2022S-ML/blob/main/HW4_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW4 :: DNN**\n",
        "## 과제 목표\n",
        "* 간단한 Three Layer Network를 구현하기\n",
        "* Pytorch를 사용하여 DNN 구현 후 학습과 테스트하기\n",
        "  \n",
        "  \n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "EXvAS7OZkg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐  이번 과제는 bb에 코랩 링크, ipynb 파일만 업로드합니다(HW3와 동일하게).   \n",
        "⭐  작성한 코드에 **간단한 주석을 반드시 달아주세요**!  \n",
        "⭐  코딩할 부분을 제외하고는 수정하지 마세요. 수정 시 감점입니다."
      ],
      "metadata": {
        "id": "k5IhqPYwmnUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문제 1 - Three Layer Network**\n",
        "```class Sigmoid```와 ```Affine```을 구현한 후 이 두 class를 사용하여 ```class ThreeLayerNet```를 완성하세요. \n",
        "* 코드 참고 : deep learning from scratch"
      ],
      "metadata": {
        "id": "OKfJ8-LiFOr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-1\n",
        "class sigmoid의 forward 함수를 구현하세요.  \n",
        "힌트) sigmoid 함수 식"
      ],
      "metadata": {
        "id": "FrrWMAJx6FUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QSI6QIBkCPWP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-1 #################\n",
        "      ############# sigmoid forward 구현 ###########\n",
        "      #############################################\n",
        "        # 한 줄로 구현\n",
        "      result = 1 / (1 + np.exp(-x)) #\bactivation function sigmoid 함수식\n",
        "      #############################################\n",
        "      \n",
        "      return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-2\n",
        "class Affine의 forward 함수를 구현하세요.  \n",
        "힌트) affine 함수 식"
      ],
      "metadata": {
        "id": "1YcAkmtN6UXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine: # Affine은 Fully Connect를 의미합니다\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      #############################################\n",
        "      ################### 문제 1-2 #################\n",
        "      ############# affine forward 구현 ############\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "      out = np.dot(x, self.params[0]) + self.params[1] # affine network -> weights * inputs 행렬곱 연산 + y절편\n",
        "      #############################################\n",
        "      \n",
        "      return out\n"
      ],
      "metadata": {
        "id": "Ds05drVvG5O_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-3\n",
        "\n",
        "  각 layer의 parameter를 ```np.random.randn()``` 를 사용하여 초기화하세요.  \n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요. \n"
      ],
      "metadata": {
        "id": "aX3vaESK6jp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-4\n",
        "  문제1-1, 2에서 구현한 class를 사용하여 ThreeLayerNet의 layer를 구성하세요.\n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요."
      ],
      "metadata": {
        "id": "qoPlnkHg_18J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, first_hidden_size, second_hidden_size, output_size):\n",
        "        I, H_1, H_2,O = input_size, first_hidden_size, second_hidden_size, output_size\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-3 #################\n",
        "      ######### parameter initialization ##########\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "      #########################################\n",
        "\n",
        "        W1 = np.random.randn(I, H_1)\n",
        "        b1 = np.zeros(H_1)\n",
        "        W2 = np.random.randn(H_1, H_2)\n",
        "        b2 = np.zeros(H_2)\n",
        "        W3 = np.random.randn(H_2, O)\n",
        "        b3 = np.zeros(O)\n",
        "        # input, first, second hidden layer, output size 각 차원에 맞게끔, 표준 정규분포를 따르는 weight 데이터 랜덤 생성 y절편은 0\n",
        "        self.layers = [\n",
        "        #############################################\n",
        "        ################### 문제 1-4 #################\n",
        "        ############### stack layers ################\n",
        "        #############################################          \n",
        "            # 코드 작성\n",
        "            Affine(W1,b1),\n",
        "            Sigmoid(),\n",
        "            Affine(W2,b2),\n",
        "            Sigmoid(),\n",
        "            Affine(W3,b3)\n",
        "            #Affine network과 activation function sigmoid 함수 차례대로 3layer만큼 배열\n",
        "        #############################################    \n",
        "        ]\n",
        "\n",
        "        # 모든 weight 를 담은 리스트 생성\n",
        "        self.params = []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VmHw4K5DG3uv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data로 모델 실행해보기\n",
        "x = np.random.randn(784, 100)\n",
        "model = ThreeLayerNet(100, 50, 30, 10)\n",
        "s = model.predict(x)\n",
        "print(s)  \n",
        "s.shape"
      ],
      "metadata": {
        "id": "SNI0xGraFAAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af0fcbd-9de2-4093-a86a-1486f0d019d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.32174382  1.33903854 -4.40835859 ...  0.76596408  1.35473857\n",
            "  -1.01853947]\n",
            " [-3.40054075  0.30790203 -1.87944125 ...  1.17069263  0.41186807\n",
            "  -0.13399957]\n",
            " [-1.16481227  0.99374155 -0.27838035 ... -0.91889078 -0.27524714\n",
            "  -3.362894  ]\n",
            " ...\n",
            " [ 0.32010244 -4.8258722  -4.47364916 ... -0.09713936 -1.5974133\n",
            "  -4.77638051]\n",
            " [ 0.44562862 -1.89986397 -1.66172805 ... -0.5647482   0.04438655\n",
            "  -2.8912411 ]\n",
            " [-3.49638275 -1.09022108 -1.97811256 ...  0.32266777 -0.27021881\n",
            "  -3.69579716]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FtZZAx7vovt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 2 - Implementing DNN using Pytorch\n",
        "문제 1에서는 Pytorch를 사용하지 않고 DNN을 구현해보았습니다.  \n",
        "문제 2에서는 Pytorch를 사용하여 DNN을 구현하고 MNIST 데이터로 분류 모델 학습을 진행합니다.\n",
        "* 코드 참고: pytorch 공식 튜토리얼"
      ],
      "metadata": {
        "id": "hOzYC0u5GfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 importing\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "LKcI43VULpeQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "WCbWy3jAMGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # training data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# data loader\n",
        "# train, test 각각의 data loader 생성\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "D9DqIegtLnz9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check loaded data**\n",
        "train_loader를 사용하여 하나의 데이터를 로드한 후 이 데이터가 어떤 숫자의 데이터인지 이미지로 확인해봅니다."
      ],
      "metadata": {
        "id": "QtJVlNT9A_KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train feature와 label을 train_loader로부터 가져오기\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "IF90dcyJPhVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386b2b84-abc7-4ac2-fd99-6d3a40be059c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([1, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지로 확인\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "00Wypwb2Pr-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0d13290a-538b-4c79-871e-e8106800fa71"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-1\n",
        "4개의 linear layer와 3개의 ReLU layer를 가진 네트워크를 구성하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "BB_Qe54pB8_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-2\n",
        "forward 함수의 빈칸을 구현하세요."
      ],
      "metadata": {
        "id": "mK5ukeeECYJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 28x28 이미지를 784 픽셀 값의 배열로 변경\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(in_features=28*28, out_features=512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #############################################\n",
        "            ################### 문제 2-1 #################\n",
        "            # 4개의 linear layer와 3개의 ReLU layer를 구성하세요\n",
        "            # (위 Linear 포함 4개, ReLU layer 포함 3개를 의미)\n",
        "            #############################################\n",
        "            \n",
        "            # 시작 차원, 끝 차원 잘 고려하여 작성하기\n",
        "            # 중간 차원은 임의로 설정 가능\n",
        "            nn.Linear(in_features=512, out_features=160),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=160, out_features=40),\n",
        "            nn.ReLU(), \n",
        "            nn.Linear(in_features=40, out_features=10)\n",
        "            #Linear layer와 Relu layer 차례대로 배열 layer 한번 거칠 때마다 in 수-> out features 수로 변함\n",
        "            #############################################\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #############################################\n",
        "        ################### 문제 2-2 #################\n",
        "        # forward 함수 구현\n",
        "        #############################################\n",
        "        # 코드 작성\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        #평탄화 작업 후 활성화 함수 뉴런 활성화 이후 뒤에서 분류기로 분류\n",
        "        #############################################\n",
        "        return logits # forward 결과 저장"
      ],
      "metadata": {
        "id": "zme9j_4hMiA2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cpu OR gpu 설정\n",
        "# gpu가 있을 경우, device로 cuda를 사용함\n",
        "# colab에서 '런타임 유형 변경'을 하면 gpu 사용할 수 있음\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "kfBLbfwUJgtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1dc6387-2534-49af-e1a3-67d85715ee1b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device) # device로 Network 전송\n",
        "print(model) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "ifGukRqQOUyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24857b0-2727-4a49-89e3-9e92d3a5b90d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=160, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=160, out_features=40, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=40, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 출력해보았던 train_features[0](1개의 데이터)에 대해서 모델 학습 결과 확인해보기\n",
        "logits = model(train_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "MdOf0Rd1VEi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e17014-535f-4f9d-f9fe-b41a671dff7e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the Network** \n",
        "epoch과 batch를 활용하여 모델을 학습시켜 봅시다."
      ],
      "metadata": {
        "id": "J5G6rO77V7OR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-3\n",
        "모델의 forward, backward, optimize 하는 부분을 주어진 칸에 구현하세요."
      ],
      "metadata": {
        "id": "n7RwQwKDCjOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "y7jdCHQphsIO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "n_epoch = 3 # the number of epochs\n",
        "n_batch = 32 # the number of batches"
      ],
      "metadata": {
        "id": "XGXKm0pHhnoO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader 설정하기\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "s3viP29EipLg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # input data 가져오기\n",
        "        # data 는 [inputs, labels]로 구성된 리스트\n",
        "        inputs, labels = data\n",
        "\n",
        "        # optimizer의 파라미터 gradient를 0으로 설정\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #############################################\n",
        "        ################### 문제 2-3 #################\n",
        "        # forward, backward, optimize \n",
        "        #############################################\n",
        "          # 코드 작성\n",
        "        # forward\n",
        "        output = model(inputs)\n",
        "        # backward\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        # optimize\n",
        "        optimizer.step()\n",
        "        #############################################\n",
        "\n",
        "        # loss 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % n_batch == 0:    # print every n_batch mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / n_batch:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "m6ByMb4whKFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfe2de2-0fd7-40a5-e250-70ab7d51b8a4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.001\n",
            "[1,    33] loss: 0.048\n",
            "[1,    65] loss: 0.076\n",
            "[1,    97] loss: 0.060\n",
            "[1,   129] loss: 0.059\n",
            "[1,   161] loss: 0.065\n",
            "[1,   193] loss: 0.048\n",
            "[1,   225] loss: 0.081\n",
            "[1,   257] loss: 0.079\n",
            "[1,   289] loss: 0.076\n",
            "[1,   321] loss: 0.061\n",
            "[1,   353] loss: 0.070\n",
            "[1,   385] loss: 0.087\n",
            "[1,   417] loss: 0.053\n",
            "[1,   449] loss: 0.077\n",
            "[1,   481] loss: 0.073\n",
            "[1,   513] loss: 0.072\n",
            "[1,   545] loss: 0.063\n",
            "[1,   577] loss: 0.057\n",
            "[1,   609] loss: 0.073\n",
            "[1,   641] loss: 0.081\n",
            "[1,   673] loss: 0.052\n",
            "[1,   705] loss: 0.051\n",
            "[1,   737] loss: 0.058\n",
            "[1,   769] loss: 0.074\n",
            "[1,   801] loss: 0.072\n",
            "[1,   833] loss: 0.065\n",
            "[1,   865] loss: 0.084\n",
            "[1,   897] loss: 0.052\n",
            "[1,   929] loss: 0.059\n",
            "[1,   961] loss: 0.057\n",
            "[1,   993] loss: 0.063\n",
            "[1,  1025] loss: 0.065\n",
            "[1,  1057] loss: 0.073\n",
            "[1,  1089] loss: 0.066\n",
            "[1,  1121] loss: 0.078\n",
            "[1,  1153] loss: 0.068\n",
            "[1,  1185] loss: 0.048\n",
            "[1,  1217] loss: 0.091\n",
            "[1,  1249] loss: 0.052\n",
            "[1,  1281] loss: 0.042\n",
            "[1,  1313] loss: 0.071\n",
            "[1,  1345] loss: 0.074\n",
            "[1,  1377] loss: 0.076\n",
            "[1,  1409] loss: 0.071\n",
            "[1,  1441] loss: 0.060\n",
            "[1,  1473] loss: 0.069\n",
            "[1,  1505] loss: 0.075\n",
            "[1,  1537] loss: 0.089\n",
            "[1,  1569] loss: 0.066\n",
            "[1,  1601] loss: 0.058\n",
            "[1,  1633] loss: 0.053\n",
            "[1,  1665] loss: 0.066\n",
            "[1,  1697] loss: 0.048\n",
            "[1,  1729] loss: 0.058\n",
            "[1,  1761] loss: 0.050\n",
            "[1,  1793] loss: 0.074\n",
            "[1,  1825] loss: 0.057\n",
            "[1,  1857] loss: 0.070\n",
            "[2,     1] loss: 0.001\n",
            "[2,    33] loss: 0.066\n",
            "[2,    65] loss: 0.072\n",
            "[2,    97] loss: 0.062\n",
            "[2,   129] loss: 0.056\n",
            "[2,   161] loss: 0.047\n",
            "[2,   193] loss: 0.061\n",
            "[2,   225] loss: 0.054\n",
            "[2,   257] loss: 0.062\n",
            "[2,   289] loss: 0.051\n",
            "[2,   321] loss: 0.048\n",
            "[2,   353] loss: 0.060\n",
            "[2,   385] loss: 0.053\n",
            "[2,   417] loss: 0.054\n",
            "[2,   449] loss: 0.068\n",
            "[2,   481] loss: 0.059\n",
            "[2,   513] loss: 0.054\n",
            "[2,   545] loss: 0.066\n",
            "[2,   577] loss: 0.059\n",
            "[2,   609] loss: 0.049\n",
            "[2,   641] loss: 0.073\n",
            "[2,   673] loss: 0.050\n",
            "[2,   705] loss: 0.057\n",
            "[2,   737] loss: 0.062\n",
            "[2,   769] loss: 0.059\n",
            "[2,   801] loss: 0.044\n",
            "[2,   833] loss: 0.045\n",
            "[2,   865] loss: 0.068\n",
            "[2,   897] loss: 0.080\n",
            "[2,   929] loss: 0.099\n",
            "[2,   961] loss: 0.045\n",
            "[2,   993] loss: 0.080\n",
            "[2,  1025] loss: 0.062\n",
            "[2,  1057] loss: 0.052\n",
            "[2,  1089] loss: 0.062\n",
            "[2,  1121] loss: 0.058\n",
            "[2,  1153] loss: 0.051\n",
            "[2,  1185] loss: 0.048\n",
            "[2,  1217] loss: 0.050\n",
            "[2,  1249] loss: 0.049\n",
            "[2,  1281] loss: 0.064\n",
            "[2,  1313] loss: 0.048\n",
            "[2,  1345] loss: 0.045\n",
            "[2,  1377] loss: 0.040\n",
            "[2,  1409] loss: 0.056\n",
            "[2,  1441] loss: 0.071\n",
            "[2,  1473] loss: 0.064\n",
            "[2,  1505] loss: 0.054\n",
            "[2,  1537] loss: 0.074\n",
            "[2,  1569] loss: 0.090\n",
            "[2,  1601] loss: 0.055\n",
            "[2,  1633] loss: 0.055\n",
            "[2,  1665] loss: 0.065\n",
            "[2,  1697] loss: 0.068\n",
            "[2,  1729] loss: 0.053\n",
            "[2,  1761] loss: 0.062\n",
            "[2,  1793] loss: 0.046\n",
            "[2,  1825] loss: 0.053\n",
            "[2,  1857] loss: 0.042\n",
            "[3,     1] loss: 0.010\n",
            "[3,    33] loss: 0.050\n",
            "[3,    65] loss: 0.053\n",
            "[3,    97] loss: 0.055\n",
            "[3,   129] loss: 0.046\n",
            "[3,   161] loss: 0.040\n",
            "[3,   193] loss: 0.052\n",
            "[3,   225] loss: 0.045\n",
            "[3,   257] loss: 0.051\n",
            "[3,   289] loss: 0.047\n",
            "[3,   321] loss: 0.054\n",
            "[3,   353] loss: 0.063\n",
            "[3,   385] loss: 0.048\n",
            "[3,   417] loss: 0.055\n",
            "[3,   449] loss: 0.043\n",
            "[3,   481] loss: 0.032\n",
            "[3,   513] loss: 0.066\n",
            "[3,   545] loss: 0.039\n",
            "[3,   577] loss: 0.047\n",
            "[3,   609] loss: 0.052\n",
            "[3,   641] loss: 0.060\n",
            "[3,   673] loss: 0.059\n",
            "[3,   705] loss: 0.046\n",
            "[3,   737] loss: 0.053\n",
            "[3,   769] loss: 0.070\n",
            "[3,   801] loss: 0.059\n",
            "[3,   833] loss: 0.064\n",
            "[3,   865] loss: 0.034\n",
            "[3,   897] loss: 0.060\n",
            "[3,   929] loss: 0.080\n",
            "[3,   961] loss: 0.046\n",
            "[3,   993] loss: 0.056\n",
            "[3,  1025] loss: 0.058\n",
            "[3,  1057] loss: 0.065\n",
            "[3,  1089] loss: 0.069\n",
            "[3,  1121] loss: 0.065\n",
            "[3,  1153] loss: 0.056\n",
            "[3,  1185] loss: 0.039\n",
            "[3,  1217] loss: 0.047\n",
            "[3,  1249] loss: 0.034\n",
            "[3,  1281] loss: 0.040\n",
            "[3,  1313] loss: 0.065\n",
            "[3,  1345] loss: 0.049\n",
            "[3,  1377] loss: 0.067\n",
            "[3,  1409] loss: 0.037\n",
            "[3,  1441] loss: 0.046\n",
            "[3,  1473] loss: 0.058\n",
            "[3,  1505] loss: 0.069\n",
            "[3,  1537] loss: 0.047\n",
            "[3,  1569] loss: 0.046\n",
            "[3,  1601] loss: 0.046\n",
            "[3,  1633] loss: 0.065\n",
            "[3,  1665] loss: 0.044\n",
            "[3,  1697] loss: 0.054\n",
            "[3,  1729] loss: 0.059\n",
            "[3,  1761] loss: 0.057\n",
            "[3,  1793] loss: 0.041\n",
            "[3,  1825] loss: 0.052\n",
            "[3,  1857] loss: 0.052\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test the Network**"
      ],
      "metadata": {
        "id": "XnqNJjGki4JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test feature와 label을 test_loader로부터 가져오기\n",
        "test_features, test_labels = next(iter(test_loader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")"
      ],
      "metadata": {
        "id": "CO1AMDEAjGrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82580d55-bd2f-4e16-c869-bd757011f809"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개 이미지 확인해보기\n",
        "\n",
        "logits = model(test_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "\n",
        "\n",
        "img = test_features[0].squeeze()\n",
        "label = test_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "bgC3vITkjWdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "8ece680e-a69b-4265-deeb-5dae0ef23506"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([4])\n",
            "Label: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 test data에 대한 결과 확인\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # 모델을 학습하는 것이 아니므로 gradient 계산을 할 필요가 없음\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "RE_tglcsmmRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7b0e2b-7771-447b-bab2-10afb9de8e0d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 97 %\n"
          ]
        }
      ]
    }
  ]
}